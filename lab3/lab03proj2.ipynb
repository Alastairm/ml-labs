{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CITS5508 Lab sheet 3</center>\n",
    "\n",
    "**Name:** Alastair Mory<br>\n",
    "**Student number:** 21120848<br>\n",
    "\n",
    "\n",
    "Two random forrest classifiers will be trialled on a task involving categorising people as healthy or having parkinsons based on 22 voice metrics. The dataset was obtained [here](https://archive.ics.uci.edu/ml/datasets/Parkinsons).\n",
    "\n",
    "<br><b>Contents</b><br>\n",
    "[1 Dataset](#1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.1 Data Visualisation and Statistics](#1.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.2 Partioning Data](#1.2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.3 Scaling and Normalisation](#1.3)<br>\n",
    "[2 Classification](#2)<br>\n",
    "[3 Conclusion](#3)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, metrics, model_selection, preprocessing, svm\n",
    "\n",
    "# Show all attribute columns in pandas tables.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset <a name=\"1\">\n",
    "\n",
    "This dataset is composed of a range of biomedical voice measurements from \n",
    "31 people, 23 with Parkinson's disease (PD). Each column in the table is a \n",
    "particular voice measure, and each row corresponds one of 195 voice \n",
    "recording from these individuals (\"name\" column). The main aim of the data \n",
    "is to discriminate healthy people from those with PD, according to \"status\" \n",
    "column which is set to 0 for healthy and 1 for PD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV\n",
    "data = pd.read_csv('./parkinsons.data')\n",
    "\n",
    "# Display example data rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Visualisation and Statistics <a name=\"1.1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of numerical features\n",
    "%matplotlib inline\n",
    "data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for numerical features\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots and statistics there are a variety of distributions with a large range of scales, many having a positive skewness (e.g. the MDVP and shimmer measures) and others having a more normal unskewed distribution (e.g. D2, DFA, HNR & spread measures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Partitioning Data <a name=\"1.2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 80/20 train test split\n",
    "train, test = model_selection.train_test_split(data,\n",
    "                                               test_size=0.2,\n",
    "                                               train_size=0.8)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "train_y = train['status']\n",
    "test_y = test['status']\n",
    "\n",
    "train_x = train.drop(columns=['name', 'status'])\n",
    "test_x = test.drop(columns=['name', 'status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Scaling and Normalisation <a name=\"1.3\"/>\n",
    "\n",
    "As per [this answer](https://stats.stackexchange.com/questions/255765/does-random-forest-need-input-variables-to-be-scaled-or-centered) from StackExchange, no scaling or normalisation is required on data using a random forest classifier:\n",
    "\n",
    ">Random Forests are based on tree partitioning algorithms.\n",
    ">\n",
    ">As such, there's no analogue to a coefficient one obtain in general regression strategies, which would depend on the units of the independent variables. Instead, one obtain a collection of partition rules, basically a decision given a threshold, and this shouldn't change with scaling. In other words, the trees only see ranks in the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classification <a name=\"2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(clf: Any,  # pretrained classifier\n",
    "                  test_x: pd.DataFrame, test_y: pd.Series,\n",
    "                  clf_name='Classifier') -> None:\n",
    "    \"\"\"\n",
    "    Run prediction using provided trained classifier and show confusion matrix, accuracy and f1 scores. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Run classifier prediction\n",
    "    pred_y = clf.predict(test_x)\n",
    "    \n",
    "    # Calculate accuracy & F1 score\n",
    "    accuracy = metrics.accuracy_score(test_y, pred_y)\n",
    "    f1 = metrics.f1_score(test_y, pred_y, average='weighted')\n",
    "    # Place in dataframe for prettier printing\n",
    "    scores = pd.DataFrame(data=[[accuracy, f1]],\n",
    "                          index=[\"\"],\n",
    "                          columns=['Accuracy', 'F1 Score'])\n",
    "    \n",
    "    # Display confusion matrix and metric scores\n",
    "    metrics.plot_confusion_matrix(clf, test_x, test_y, \n",
    "                              normalize='true',\n",
    "                              cmap=plt.cm.Blues,)\n",
    "    print(f\"{clf_name} Metrics\\n\")\n",
    "    print(f\"{scores}\\n\")\n",
    "    print(f\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ensemble.RandomForestClassifier(n_estimators=100, criterion='gini').fit(train_x, train_y)\n",
    "clf2 = ensemble.RandomForestClassifier(n_estimators=10, criterion='gini').fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_metrics(clf1, test_x, test_y, 'Random Forest 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_metrics(clf2, test_x, test_y, 'Random Forest 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conclusion <a name=\"3\"/>\n",
    "\n",
    "As there was no obvious difference between the two split quality criterion parameters (gini & entropy), the default of gini was used for both classifiers. The hyperparameter that was varied was the n_estimators parameter, which specifies the number of trees in the forrest. The first using sklearn's default of 100 has relatively stable performance (with both measures usually aroung 85%); the second classifier uses a value of 10, this results in more varied performance (generally 80-95%) but on average higher accuracy and f1 scores. This suggests the classifier with more trees (classifier 1) has a tendency to overfit and classifier 2 with less trees is generalising better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
