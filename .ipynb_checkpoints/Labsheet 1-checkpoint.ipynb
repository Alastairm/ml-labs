{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Labsheet 1\n",
    "=========\n",
    "\n",
    "### Chapter 1 & 2 Fuckaround"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 1\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 2\n",
    "\n",
    "Housing Values and stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll just dump all the imports here, they'll all share the same namespace anyway\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib\n",
    "from zlib import crc32\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Measures and Notations\n",
    "\n",
    "$\\textbf{Root Mean Square Error}$ (RMSE, aka Root Mean Square Deviation or RMSD) is a commonly used performance measure for a regression analysis. It measures the standard deviation of the errors made in the system's predictions.\n",
    "\n",
    "$$\\text{RMSE}(\\mathbf{X},h) = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} \\Big( h(\\mathbf{x}^i) - y^i \\Big)^2}$$\n",
    "\n",
    "* $m$ Number of instances in the dataset.\n",
    "* $\\textbf{x^i}$ is a vector containgin all the feature values for a given instance.\n",
    "* $\\textbf{X}$ is a matrix containing all the feature values of all instances contained within the dataset.\n",
    "* $y^i$ is the value being predicted by the system (aka the $\\mathit{label}$)\n",
    "\n",
    "* $h$ is the system's prediction function (aka the' $\\mathit{hypothesis}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this a function because we really only want to run it once\n",
    "URL_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "DIR_NAME = \"datasets/housing/\"\n",
    "\n",
    "def fetch_housing_data():\n",
    "    dir_path = DIR_NAME\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    housing_path = DIR_NAME + \"housing.tgz\"\n",
    "    with open(housing_path, 'wb') as archive_file:\n",
    "        data_url = URL_ROOT + DIR_NAME + \"housing.tgz\"\n",
    "        with urllib.request.urlopen(data_url) as response:\n",
    "            shutil.copyfileobj(response, archive_file)\n",
    "    with tarfile.open(housing_path) as archive_file:\n",
    "        archive_file.extractall(dir_path)\n",
    "\n",
    "def load_housing_data():\n",
    "    csv_path = DIR_NAME + \"housing.csv\"\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "#fetch_housing_data()\n",
    "housing = load_housing_data()\n",
    "print(housing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20433 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data\n",
    "housing.head()\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Test Set\n",
    "\n",
    "To avoid overfitting the training model it's important not to evaluate a system with the same data that was used to train it. The simplest solution is to split the dataset into a training and a validation set. The textbook says 80-20 is not a bad split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "housing_with_id = housing.reset_index()   # adds an `index` column\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
